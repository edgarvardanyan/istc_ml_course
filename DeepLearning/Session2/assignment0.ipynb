{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The easiest assignment in this course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cope one of these notebooks (`Linear SoftMax Classifier.ipynb`, `Polynomial SoftMax Classifier.ipynb`) and replace the model with multilayer neural network. Play with nonlinearities, also generate your own, more entangled data and check your models perfrmance. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6cd41cc400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "N = 100 # number of points per class\n",
    "D = 2 # dimensionality\n",
    "K = 3 # number of classes\n",
    "X = np.zeros((N*K,D)) # data matrix (each row = single example)\n",
    "y = np.zeros(N*K, dtype='uint8') # class labels\n",
    "for j in range(K):\n",
    "    ix = range(N*j,N*(j+1))\n",
    "    r = np.linspace(0.0,1,N) # radius\n",
    "    t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
    "    X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "    y[ix] = j\n",
    "X[:, 0] += 1\n",
    "X[:, 1] += 2\n",
    "# lets visualize the data:\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral, edgecolors=\"black\")\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(h=0.02):\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                 np.arange(y_min, y_max, h))\n",
    "    Z = sess.run(t_prediction, feed_dict={t_x: np.column_stack([xx.ravel(), yy.ravel()])})\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral, edgecolors=\"black\")\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Linear SoftMax Classifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "t_x = tf.placeholder(tf.float32, shape=[None, D])\n",
    "t_y = tf.placeholder(tf.int32, shape=[None])\n",
    "W = tf.Variable(tf.random_normal([D, K]))\n",
    "b = tf.Variable(tf.zeros([1, K], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# some hyperparameters\n",
    "step_size = 1e-0\n",
    "reg = 1e-3 # regularization strength\n",
    "\n",
    "t_scores = tf.matmul(t_x, W) + b\n",
    "t_prediction = tf.argmax(t_scores, axis=-1, output_type=tf.int32)\n",
    "t_acc = tf.reduce_mean(tf.cast(tf.equal(t_prediction, t_y), tf.float32))\n",
    "t_loss_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=t_y, logits=t_scores)\n",
    "t_loss_reg = tf.reduce_sum(W * W) * reg\n",
    "t_loss = tf.reduce_mean(t_loss_entropy + t_loss_reg)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=step_size)\n",
    "\n",
    "train_op = optimizer.minimize(t_loss)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if \"sess\" in dir():\n",
    "    sess.close()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# plot the resulting classifier\n",
    "plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for i in range(20):\n",
    "    loss, acc, _ = sess.run([t_loss, t_acc, train_op], feed_dict={t_x:X, t_y:y})\n",
    "#     time.sleep(0.1)\n",
    "    \n",
    "    if i % 2 == 0:\n",
    "        print(\"iteration %d:\\tloss %f\\tacc %f\" % (i, loss, acc))\n",
    "        clear_output(wait=True)\n",
    "        plot(h=0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# evaluate training set accuracy\n",
    "print('training accuracy: %.2f%%' % (100*sess.run(t_acc, feed_dict={t_x:X, t_y:y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neaural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_X = tf.placeholder(tf.float32, shape = [None, 2], name = 'inputs')\n",
    "target_y = tf.placeholder(tf.int32, shape = [None], name = 'target')\n",
    "l1 = tf.layers.dense(input_X, units = 20, activation = tf.nn.relu)\n",
    "l2 = tf.layers.dense(l1, units = 3, activation = None)\n",
    "l_out = tf.nn.softmax(l2, name = 'predict_proba')\n",
    "y_predicted = tf.argmax(l2, axis = 1)\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    labels=target_y, logits=l2, name=\"softmax_loss\"))\n",
    "accuracy, update_accuracy = tf.metrics.accuracy(target_y, y_predicted)\n",
    "optimzer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_step = optimzer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize):\n",
    "    assert len(inputs) == len(targets)\n",
    "    indices = np.arange(len(inputs))\n",
    "    np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1000 took 0.122s\n",
      "  training loss (in-iteration):\t\t1.236402\n",
      "  train accuracy:\t\t33.33 %\n",
      "Epoch 2 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.189452\n",
      "  train accuracy:\t\t33.33 %\n",
      "Epoch 3 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.157108\n",
      "  train accuracy:\t\t35.67 %\n",
      "Epoch 4 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.137658\n",
      "  train accuracy:\t\t30.67 %\n",
      "Epoch 5 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.128075\n",
      "  train accuracy:\t\t35.33 %\n",
      "Epoch 6 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.124993\n",
      "  train accuracy:\t\t29.00 %\n",
      "Epoch 7 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.124621\n",
      "  train accuracy:\t\t25.00 %\n",
      "Epoch 8 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.123614\n",
      "  train accuracy:\t\t23.00 %\n",
      "Epoch 9 of 1000 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.120501\n",
      "  train accuracy:\t\t23.67 %\n",
      "Epoch 10 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t1.115163\n",
      "  train accuracy:\t\t25.00 %\n",
      "Epoch 11 of 1000 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.108073\n",
      "  train accuracy:\t\t28.33 %\n",
      "Epoch 12 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.099830\n",
      "  train accuracy:\t\t36.67 %\n",
      "Epoch 13 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.091159\n",
      "  train accuracy:\t\t40.67 %\n",
      "Epoch 14 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.082630\n",
      "  train accuracy:\t\t40.67 %\n",
      "Epoch 15 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.074531\n",
      "  train accuracy:\t\t40.67 %\n",
      "Epoch 16 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.067140\n",
      "  train accuracy:\t\t41.00 %\n",
      "Epoch 17 of 1000 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.060573\n",
      "  train accuracy:\t\t41.67 %\n",
      "Epoch 18 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.054757\n",
      "  train accuracy:\t\t50.67 %\n",
      "Epoch 19 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.049459\n",
      "  train accuracy:\t\t53.67 %\n",
      "Epoch 20 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.044379\n",
      "  train accuracy:\t\t58.33 %\n",
      "Epoch 21 of 1000 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.039249\n",
      "  train accuracy:\t\t60.33 %\n",
      "Epoch 22 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.033858\n",
      "  train accuracy:\t\t60.00 %\n",
      "Epoch 23 of 1000 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.027966\n",
      "  train accuracy:\t\t58.67 %\n",
      "Epoch 24 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.021598\n",
      "  train accuracy:\t\t59.33 %\n",
      "Epoch 25 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.014831\n",
      "  train accuracy:\t\t60.67 %\n",
      "Epoch 26 of 1000 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.007727\n",
      "  train accuracy:\t\t61.67 %\n",
      "Epoch 27 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.000363\n",
      "  train accuracy:\t\t62.00 %\n",
      "Epoch 28 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.992677\n",
      "  train accuracy:\t\t62.00 %\n",
      "Epoch 29 of 1000 took 0.074s\n",
      "  training loss (in-iteration):\t\t0.985058\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 30 of 1000 took 0.075s\n",
      "  training loss (in-iteration):\t\t0.977770\n",
      "  train accuracy:\t\t63.00 %\n",
      "Epoch 31 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.970825\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 32 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.964199\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 33 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.957782\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 34 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t0.951546\n",
      "  train accuracy:\t\t62.67 %\n",
      "Epoch 35 of 1000 took 0.077s\n",
      "  training loss (in-iteration):\t\t0.945321\n",
      "  train accuracy:\t\t63.00 %\n",
      "Epoch 36 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.938950\n",
      "  train accuracy:\t\t63.00 %\n",
      "Epoch 37 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.932513\n",
      "  train accuracy:\t\t63.33 %\n",
      "Epoch 38 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.926085\n",
      "  train accuracy:\t\t63.67 %\n",
      "Epoch 39 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.919788\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 40 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.913708\n",
      "  train accuracy:\t\t63.33 %\n",
      "Epoch 41 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.907857\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 42 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.902163\n",
      "  train accuracy:\t\t61.33 %\n",
      "Epoch 43 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t0.896521\n",
      "  train accuracy:\t\t61.00 %\n",
      "Epoch 44 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.890880\n",
      "  train accuracy:\t\t61.00 %\n",
      "Epoch 45 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.885228\n",
      "  train accuracy:\t\t61.00 %\n",
      "Epoch 46 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.879585\n",
      "  train accuracy:\t\t62.00 %\n",
      "Epoch 47 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.874034\n",
      "  train accuracy:\t\t63.33 %\n",
      "Epoch 48 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.868643\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 49 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.863467\n",
      "  train accuracy:\t\t64.33 %\n",
      "Epoch 50 of 1000 took 0.076s\n",
      "  training loss (in-iteration):\t\t0.858512\n",
      "  train accuracy:\t\t64.33 %\n",
      "Epoch 51 of 1000 took 0.077s\n",
      "  training loss (in-iteration):\t\t0.853715\n",
      "  train accuracy:\t\t64.33 %\n",
      "Epoch 52 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.849024\n",
      "  train accuracy:\t\t64.33 %\n",
      "Epoch 53 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.844465\n",
      "  train accuracy:\t\t63.67 %\n",
      "Epoch 54 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.839983\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 55 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.835575\n",
      "  train accuracy:\t\t63.00 %\n",
      "Epoch 56 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.831291\n",
      "  train accuracy:\t\t62.67 %\n",
      "Epoch 57 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.827207\n",
      "  train accuracy:\t\t62.67 %\n",
      "Epoch 58 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.823291\n",
      "  train accuracy:\t\t62.00 %\n",
      "Epoch 59 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.819483\n",
      "  train accuracy:\t\t61.00 %\n",
      "Epoch 60 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.815743\n",
      "  train accuracy:\t\t60.33 %\n",
      "Epoch 61 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t0.812078\n",
      "  train accuracy:\t\t60.33 %\n",
      "Epoch 62 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.808499\n",
      "  train accuracy:\t\t60.00 %\n",
      "Epoch 63 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.805001\n",
      "  train accuracy:\t\t60.67 %\n",
      "Epoch 64 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.801612\n",
      "  train accuracy:\t\t61.00 %\n",
      "Epoch 65 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.798347\n",
      "  train accuracy:\t\t61.33 %\n",
      "Epoch 66 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.795179\n",
      "  train accuracy:\t\t61.33 %\n",
      "Epoch 67 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.792054\n",
      "  train accuracy:\t\t61.00 %\n",
      "Epoch 68 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.788977\n",
      "  train accuracy:\t\t60.67 %\n",
      "Epoch 69 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.785968\n",
      "  train accuracy:\t\t60.33 %\n",
      "Epoch 70 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.783024\n",
      "  train accuracy:\t\t60.00 %\n",
      "Epoch 71 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.780150\n",
      "  train accuracy:\t\t59.67 %\n",
      "Epoch 72 of 1000 took 0.087s\n",
      "  training loss (in-iteration):\t\t0.777355\n",
      "  train accuracy:\t\t59.33 %\n",
      "Epoch 73 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t0.774627\n",
      "  train accuracy:\t\t58.67 %\n",
      "Epoch 74 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.771948\n",
      "  train accuracy:\t\t58.67 %\n",
      "Epoch 75 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.769316\n",
      "  train accuracy:\t\t58.67 %\n",
      "Epoch 76 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.766753\n",
      "  train accuracy:\t\t58.67 %\n",
      "Epoch 77 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t0.764256\n",
      "  train accuracy:\t\t59.00 %\n",
      "Epoch 78 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.761836\n",
      "  train accuracy:\t\t59.00 %\n",
      "Epoch 79 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.759479\n",
      "  train accuracy:\t\t59.00 %\n",
      "Epoch 80 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.757181\n",
      "  train accuracy:\t\t59.00 %\n",
      "Epoch 81 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.754933\n",
      "  train accuracy:\t\t58.67 %\n",
      "Epoch 82 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.752742\n",
      "  train accuracy:\t\t58.33 %\n",
      "Epoch 83 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.750616\n",
      "  train accuracy:\t\t58.00 %\n",
      "Epoch 84 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.748544\n",
      "  train accuracy:\t\t57.33 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.746524\n",
      "  train accuracy:\t\t57.33 %\n",
      "Epoch 86 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.744570\n",
      "  train accuracy:\t\t57.00 %\n",
      "Epoch 87 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.742661\n",
      "  train accuracy:\t\t57.00 %\n",
      "Epoch 88 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.740811\n",
      "  train accuracy:\t\t57.00 %\n",
      "Epoch 89 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.739011\n",
      "  train accuracy:\t\t57.33 %\n",
      "Epoch 90 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.737255\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 91 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.735551\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 92 of 1000 took 0.077s\n",
      "  training loss (in-iteration):\t\t0.733896\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 93 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.732285\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 94 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.730720\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 95 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.729198\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 96 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.727720\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 97 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.726282\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 98 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.724882\n",
      "  train accuracy:\t\t56.33 %\n",
      "Epoch 99 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t0.723515\n",
      "  train accuracy:\t\t56.33 %\n",
      "Epoch 100 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.722180\n",
      "  train accuracy:\t\t56.33 %\n",
      "Epoch 101 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.720877\n",
      "  train accuracy:\t\t56.33 %\n",
      "Epoch 102 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.719592\n",
      "  train accuracy:\t\t56.33 %\n",
      "Epoch 103 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.718330\n",
      "  train accuracy:\t\t57.00 %\n",
      "Epoch 104 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.717094\n",
      "  train accuracy:\t\t56.33 %\n",
      "Epoch 105 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.715897\n",
      "  train accuracy:\t\t56.33 %\n",
      "Epoch 106 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.714723\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 107 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.713574\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 108 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.712447\n",
      "  train accuracy:\t\t57.00 %\n",
      "Epoch 109 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.711341\n",
      "  train accuracy:\t\t57.00 %\n",
      "Epoch 110 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.710257\n",
      "  train accuracy:\t\t57.00 %\n",
      "Epoch 111 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.709189\n",
      "  train accuracy:\t\t57.00 %\n",
      "Epoch 112 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.708139\n",
      "  train accuracy:\t\t57.00 %\n",
      "Epoch 113 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.707095\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 114 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t0.706058\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 115 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.705022\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 116 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.703981\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 117 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.702934\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 118 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.701870\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 119 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.700794\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 120 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.699749\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 121 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.698712\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 122 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.697680\n",
      "  train accuracy:\t\t56.67 %\n",
      "Epoch 123 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.696676\n",
      "  train accuracy:\t\t57.00 %\n",
      "Epoch 124 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.695654\n",
      "  train accuracy:\t\t57.33 %\n",
      "Epoch 125 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.694636\n",
      "  train accuracy:\t\t57.33 %\n",
      "Epoch 126 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.693618\n",
      "  train accuracy:\t\t57.33 %\n",
      "Epoch 127 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t0.692581\n",
      "  train accuracy:\t\t57.33 %\n",
      "Epoch 128 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.691553\n",
      "  train accuracy:\t\t57.67 %\n",
      "Epoch 129 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.690531\n",
      "  train accuracy:\t\t57.67 %\n",
      "Epoch 130 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t0.689485\n",
      "  train accuracy:\t\t58.00 %\n",
      "Epoch 131 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.688462\n",
      "  train accuracy:\t\t58.00 %\n",
      "Epoch 132 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.687454\n",
      "  train accuracy:\t\t58.00 %\n",
      "Epoch 133 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.686449\n",
      "  train accuracy:\t\t58.33 %\n",
      "Epoch 134 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.685440\n",
      "  train accuracy:\t\t58.67 %\n",
      "Epoch 135 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.684414\n",
      "  train accuracy:\t\t58.67 %\n",
      "Epoch 136 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.683380\n",
      "  train accuracy:\t\t59.00 %\n",
      "Epoch 137 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.682338\n",
      "  train accuracy:\t\t59.33 %\n",
      "Epoch 138 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.681279\n",
      "  train accuracy:\t\t59.33 %\n",
      "Epoch 139 of 1000 took 0.087s\n",
      "  training loss (in-iteration):\t\t0.680212\n",
      "  train accuracy:\t\t59.33 %\n",
      "Epoch 140 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.679145\n",
      "  train accuracy:\t\t59.33 %\n",
      "Epoch 141 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.678103\n",
      "  train accuracy:\t\t59.33 %\n",
      "Epoch 142 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t0.677036\n",
      "  train accuracy:\t\t59.67 %\n",
      "Epoch 143 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.675969\n",
      "  train accuracy:\t\t59.67 %\n",
      "Epoch 144 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.674903\n",
      "  train accuracy:\t\t59.67 %\n",
      "Epoch 145 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t0.673825\n",
      "  train accuracy:\t\t59.67 %\n",
      "Epoch 146 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.672744\n",
      "  train accuracy:\t\t60.33 %\n",
      "Epoch 147 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.671645\n",
      "  train accuracy:\t\t60.33 %\n",
      "Epoch 148 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.670536\n",
      "  train accuracy:\t\t60.00 %\n",
      "Epoch 149 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.669436\n",
      "  train accuracy:\t\t60.00 %\n",
      "Epoch 150 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.668336\n",
      "  train accuracy:\t\t60.00 %\n",
      "Epoch 151 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.667229\n",
      "  train accuracy:\t\t60.00 %\n",
      "Epoch 152 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.666137\n",
      "  train accuracy:\t\t60.67 %\n",
      "Epoch 153 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.665045\n",
      "  train accuracy:\t\t60.67 %\n",
      "Epoch 154 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.663945\n",
      "  train accuracy:\t\t60.67 %\n",
      "Epoch 155 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.662844\n",
      "  train accuracy:\t\t60.33 %\n",
      "Epoch 156 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.661758\n",
      "  train accuracy:\t\t60.67 %\n",
      "Epoch 157 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.660671\n",
      "  train accuracy:\t\t60.67 %\n",
      "Epoch 158 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.659576\n",
      "  train accuracy:\t\t60.67 %\n",
      "Epoch 159 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.658477\n",
      "  train accuracy:\t\t60.67 %\n",
      "Epoch 160 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.657365\n",
      "  train accuracy:\t\t61.00 %\n",
      "Epoch 161 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.656231\n",
      "  train accuracy:\t\t61.00 %\n",
      "Epoch 162 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.655101\n",
      "  train accuracy:\t\t61.67 %\n",
      "Epoch 163 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.653965\n",
      "  train accuracy:\t\t61.67 %\n",
      "Epoch 164 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.652826\n",
      "  train accuracy:\t\t61.67 %\n",
      "Epoch 165 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.651683\n",
      "  train accuracy:\t\t61.67 %\n",
      "Epoch 166 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.650532\n",
      "  train accuracy:\t\t61.67 %\n",
      "Epoch 167 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.649386\n",
      "  train accuracy:\t\t62.00 %\n",
      "Epoch 168 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.648224\n",
      "  train accuracy:\t\t62.00 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.647037\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 170 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.645853\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 171 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.644641\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 172 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.643425\n",
      "  train accuracy:\t\t62.67 %\n",
      "Epoch 173 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.642256\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 174 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.641093\n",
      "  train accuracy:\t\t62.00 %\n",
      "Epoch 175 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.639936\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 176 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.638756\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 177 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.637567\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 178 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.636370\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 179 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.635189\n",
      "  train accuracy:\t\t62.33 %\n",
      "Epoch 180 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.634016\n",
      "  train accuracy:\t\t63.33 %\n",
      "Epoch 181 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.632847\n",
      "  train accuracy:\t\t63.67 %\n",
      "Epoch 182 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.631664\n",
      "  train accuracy:\t\t63.33 %\n",
      "Epoch 183 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.630472\n",
      "  train accuracy:\t\t63.33 %\n",
      "Epoch 184 of 1000 took 0.087s\n",
      "  training loss (in-iteration):\t\t0.629274\n",
      "  train accuracy:\t\t63.33 %\n",
      "Epoch 185 of 1000 took 0.077s\n",
      "  training loss (in-iteration):\t\t0.628075\n",
      "  train accuracy:\t\t63.33 %\n",
      "Epoch 186 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.626891\n",
      "  train accuracy:\t\t63.67 %\n",
      "Epoch 187 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.625716\n",
      "  train accuracy:\t\t63.67 %\n",
      "Epoch 188 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.624525\n",
      "  train accuracy:\t\t63.67 %\n",
      "Epoch 189 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.623343\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 190 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t0.622164\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 191 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.620980\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 192 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.619796\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 193 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.618606\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 194 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.617417\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 195 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.616226\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 196 of 1000 took 0.087s\n",
      "  training loss (in-iteration):\t\t0.615035\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 197 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.613846\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 198 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.612655\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 199 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.611462\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 200 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.610255\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 201 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.609047\n",
      "  train accuracy:\t\t64.00 %\n",
      "Epoch 202 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t0.607832\n",
      "  train accuracy:\t\t64.67 %\n",
      "Epoch 203 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.606602\n",
      "  train accuracy:\t\t64.33 %\n",
      "Epoch 204 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.605377\n",
      "  train accuracy:\t\t64.67 %\n",
      "Epoch 205 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t0.604158\n",
      "  train accuracy:\t\t65.00 %\n",
      "Epoch 206 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.602938\n",
      "  train accuracy:\t\t65.00 %\n",
      "Epoch 207 of 1000 took 0.077s\n",
      "  training loss (in-iteration):\t\t0.601698\n",
      "  train accuracy:\t\t65.00 %\n",
      "Epoch 208 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.600462\n",
      "  train accuracy:\t\t65.33 %\n",
      "Epoch 209 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.599225\n",
      "  train accuracy:\t\t65.33 %\n",
      "Epoch 210 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.597978\n",
      "  train accuracy:\t\t65.67 %\n",
      "Epoch 211 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.596726\n",
      "  train accuracy:\t\t66.33 %\n",
      "Epoch 212 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.595462\n",
      "  train accuracy:\t\t66.33 %\n",
      "Epoch 213 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.594211\n",
      "  train accuracy:\t\t66.33 %\n",
      "Epoch 214 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.592950\n",
      "  train accuracy:\t\t66.67 %\n",
      "Epoch 215 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.591678\n",
      "  train accuracy:\t\t66.67 %\n",
      "Epoch 216 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.590409\n",
      "  train accuracy:\t\t66.67 %\n",
      "Epoch 217 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t0.589147\n",
      "  train accuracy:\t\t66.67 %\n",
      "Epoch 218 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.587871\n",
      "  train accuracy:\t\t66.67 %\n",
      "Epoch 219 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.586583\n",
      "  train accuracy:\t\t67.00 %\n",
      "Epoch 220 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.585306\n",
      "  train accuracy:\t\t67.33 %\n",
      "Epoch 221 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.584030\n",
      "  train accuracy:\t\t67.67 %\n",
      "Epoch 222 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.582739\n",
      "  train accuracy:\t\t68.00 %\n",
      "Epoch 223 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.581472\n",
      "  train accuracy:\t\t68.00 %\n",
      "Epoch 224 of 1000 took 0.078s\n",
      "  training loss (in-iteration):\t\t0.580193\n",
      "  train accuracy:\t\t68.33 %\n",
      "Epoch 225 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.578901\n",
      "  train accuracy:\t\t68.33 %\n",
      "Epoch 226 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.577606\n",
      "  train accuracy:\t\t68.67 %\n",
      "Epoch 227 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.576323\n",
      "  train accuracy:\t\t68.67 %\n",
      "Epoch 228 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.575039\n",
      "  train accuracy:\t\t68.67 %\n",
      "Epoch 229 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.573746\n",
      "  train accuracy:\t\t68.67 %\n",
      "Epoch 230 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.572467\n",
      "  train accuracy:\t\t69.00 %\n",
      "Epoch 231 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.571178\n",
      "  train accuracy:\t\t69.33 %\n",
      "Epoch 232 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.569895\n",
      "  train accuracy:\t\t69.33 %\n",
      "Epoch 233 of 1000 took 0.081s\n",
      "  training loss (in-iteration):\t\t0.568609\n",
      "  train accuracy:\t\t69.33 %\n",
      "Epoch 234 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.567320\n",
      "  train accuracy:\t\t69.33 %\n",
      "Epoch 235 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.566040\n",
      "  train accuracy:\t\t69.33 %\n",
      "Epoch 236 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.564746\n",
      "  train accuracy:\t\t69.67 %\n",
      "Epoch 237 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.563457\n",
      "  train accuracy:\t\t70.00 %\n",
      "Epoch 238 of 1000 took 0.087s\n",
      "  training loss (in-iteration):\t\t0.562168\n",
      "  train accuracy:\t\t70.33 %\n",
      "Epoch 239 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.560881\n",
      "  train accuracy:\t\t70.33 %\n",
      "Epoch 240 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.559588\n",
      "  train accuracy:\t\t70.33 %\n",
      "Epoch 241 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t0.558299\n",
      "  train accuracy:\t\t70.33 %\n",
      "Epoch 242 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.557009\n",
      "  train accuracy:\t\t70.33 %\n",
      "Epoch 243 of 1000 took 0.080s\n",
      "  training loss (in-iteration):\t\t0.555719\n",
      "  train accuracy:\t\t70.67 %\n",
      "Epoch 244 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.554423\n",
      "  train accuracy:\t\t70.67 %\n",
      "Epoch 245 of 1000 took 0.077s\n",
      "  training loss (in-iteration):\t\t0.553129\n",
      "  train accuracy:\t\t71.00 %\n",
      "Epoch 246 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.551838\n",
      "  train accuracy:\t\t70.67 %\n",
      "Epoch 247 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.550549\n",
      "  train accuracy:\t\t70.67 %\n",
      "Epoch 248 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.549251\n",
      "  train accuracy:\t\t71.00 %\n",
      "Epoch 249 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.547950\n",
      "  train accuracy:\t\t71.00 %\n",
      "Epoch 250 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.546650\n",
      "  train accuracy:\t\t71.33 %\n",
      "Epoch 251 of 1000 took 0.087s\n",
      "  training loss (in-iteration):\t\t0.545371\n",
      "  train accuracy:\t\t71.33 %\n",
      "Epoch 252 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t0.544081\n",
      "  train accuracy:\t\t72.00 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t0.542784\n",
      "  train accuracy:\t\t72.33 %\n",
      "Epoch 254 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t0.541499\n",
      "  train accuracy:\t\t72.67 %\n",
      "Epoch 255 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.540214\n",
      "  train accuracy:\t\t72.67 %\n",
      "Epoch 256 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.538941\n",
      "  train accuracy:\t\t72.33 %\n",
      "Epoch 257 of 1000 took 0.084s\n",
      "  training loss (in-iteration):\t\t0.537667\n",
      "  train accuracy:\t\t72.33 %\n",
      "Epoch 258 of 1000 took 0.087s\n",
      "  training loss (in-iteration):\t\t0.536380\n",
      "  train accuracy:\t\t72.67 %\n",
      "Epoch 259 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t0.535100\n",
      "  train accuracy:\t\t72.67 %\n",
      "Epoch 260 of 1000 took 0.079s\n",
      "  training loss (in-iteration):\t\t0.533828\n",
      "  train accuracy:\t\t72.67 %\n",
      "Epoch 261 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.532552\n",
      "  train accuracy:\t\t72.67 %\n",
      "Epoch 262 of 1000 took 0.082s\n",
      "  training loss (in-iteration):\t\t0.531269\n",
      "  train accuracy:\t\t72.67 %\n",
      "Epoch 263 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.529993\n",
      "  train accuracy:\t\t72.67 %\n",
      "Epoch 264 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.528706\n",
      "  train accuracy:\t\t73.00 %\n",
      "Epoch 265 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.527428\n",
      "  train accuracy:\t\t73.33 %\n",
      "Epoch 266 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.526140\n",
      "  train accuracy:\t\t73.67 %\n",
      "Epoch 267 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.524863\n",
      "  train accuracy:\t\t73.67 %\n",
      "Epoch 268 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.523582\n",
      "  train accuracy:\t\t74.00 %\n",
      "Epoch 269 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.522309\n",
      "  train accuracy:\t\t74.00 %\n",
      "Epoch 270 of 1000 took 0.086s\n",
      "  training loss (in-iteration):\t\t0.521023\n",
      "  train accuracy:\t\t74.00 %\n",
      "Epoch 271 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.519738\n",
      "  train accuracy:\t\t74.00 %\n",
      "Epoch 272 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.518455\n",
      "  train accuracy:\t\t74.00 %\n",
      "Epoch 273 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.517180\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 274 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.515902\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 275 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.514618\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 276 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.513337\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 277 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.512067\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 278 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.510795\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 279 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.509519\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 280 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.508249\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 281 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.506977\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 282 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.505711\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 283 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.504436\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 284 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.503165\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 285 of 1000 took 0.087s\n",
      "  training loss (in-iteration):\t\t0.501897\n",
      "  train accuracy:\t\t74.33 %\n",
      "Epoch 286 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.500627\n",
      "  train accuracy:\t\t74.67 %\n",
      "Epoch 287 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.499356\n",
      "  train accuracy:\t\t74.67 %\n",
      "Epoch 288 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.498095\n",
      "  train accuracy:\t\t74.67 %\n",
      "Epoch 289 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.496831\n",
      "  train accuracy:\t\t74.67 %\n",
      "Epoch 290 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.495561\n",
      "  train accuracy:\t\t75.00 %\n",
      "Epoch 291 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.494290\n",
      "  train accuracy:\t\t74.67 %\n",
      "Epoch 292 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.493019\n",
      "  train accuracy:\t\t74.67 %\n",
      "Epoch 293 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.491747\n",
      "  train accuracy:\t\t74.67 %\n",
      "Epoch 294 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.490472\n",
      "  train accuracy:\t\t74.67 %\n",
      "Epoch 295 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.489199\n",
      "  train accuracy:\t\t75.00 %\n",
      "Epoch 296 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.487923\n",
      "  train accuracy:\t\t75.00 %\n",
      "Epoch 297 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.486650\n",
      "  train accuracy:\t\t75.00 %\n",
      "Epoch 298 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.485367\n",
      "  train accuracy:\t\t75.00 %\n",
      "Epoch 299 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.484068\n",
      "  train accuracy:\t\t75.00 %\n",
      "Epoch 300 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.482749\n",
      "  train accuracy:\t\t75.33 %\n",
      "Epoch 301 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.481438\n",
      "  train accuracy:\t\t75.00 %\n",
      "Epoch 302 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.480136\n",
      "  train accuracy:\t\t75.33 %\n",
      "Epoch 303 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.478848\n",
      "  train accuracy:\t\t75.67 %\n",
      "Epoch 304 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.477548\n",
      "  train accuracy:\t\t75.67 %\n",
      "Epoch 305 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.476232\n",
      "  train accuracy:\t\t75.67 %\n",
      "Epoch 306 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.474901\n",
      "  train accuracy:\t\t76.00 %\n",
      "Epoch 307 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.473563\n",
      "  train accuracy:\t\t75.67 %\n",
      "Epoch 308 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.472242\n",
      "  train accuracy:\t\t76.00 %\n",
      "Epoch 309 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.470934\n",
      "  train accuracy:\t\t76.00 %\n",
      "Epoch 310 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.469618\n",
      "  train accuracy:\t\t76.00 %\n",
      "Epoch 311 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.468294\n",
      "  train accuracy:\t\t76.33 %\n",
      "Epoch 312 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.466962\n",
      "  train accuracy:\t\t76.33 %\n",
      "Epoch 313 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.465625\n",
      "  train accuracy:\t\t76.33 %\n",
      "Epoch 314 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.464286\n",
      "  train accuracy:\t\t76.33 %\n",
      "Epoch 315 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.462947\n",
      "  train accuracy:\t\t76.33 %\n",
      "Epoch 316 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.461622\n",
      "  train accuracy:\t\t76.33 %\n",
      "Epoch 317 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.460314\n",
      "  train accuracy:\t\t76.33 %\n",
      "Epoch 318 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.459012\n",
      "  train accuracy:\t\t76.33 %\n",
      "Epoch 319 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.457685\n",
      "  train accuracy:\t\t76.33 %\n",
      "Epoch 320 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.456367\n",
      "  train accuracy:\t\t76.67 %\n",
      "Epoch 321 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.455070\n",
      "  train accuracy:\t\t77.33 %\n",
      "Epoch 322 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.453799\n",
      "  train accuracy:\t\t77.33 %\n",
      "Epoch 323 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.452502\n",
      "  train accuracy:\t\t77.67 %\n",
      "Epoch 324 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.451196\n",
      "  train accuracy:\t\t77.33 %\n",
      "Epoch 325 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.449881\n",
      "  train accuracy:\t\t77.33 %\n",
      "Epoch 326 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.448596\n",
      "  train accuracy:\t\t77.33 %\n",
      "Epoch 327 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.447325\n",
      "  train accuracy:\t\t77.67 %\n",
      "Epoch 328 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.446044\n",
      "  train accuracy:\t\t78.00 %\n",
      "Epoch 329 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.444752\n",
      "  train accuracy:\t\t78.00 %\n",
      "Epoch 330 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.443462\n",
      "  train accuracy:\t\t78.33 %\n",
      "Epoch 331 of 1000 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.442203\n",
      "  train accuracy:\t\t78.33 %\n",
      "Epoch 332 of 1000 took 0.122s\n",
      "  training loss (in-iteration):\t\t0.440934\n",
      "  train accuracy:\t\t78.33 %\n",
      "Epoch 333 of 1000 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.439651\n",
      "  train accuracy:\t\t78.33 %\n",
      "Epoch 334 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.438370\n",
      "  train accuracy:\t\t78.33 %\n",
      "Epoch 335 of 1000 took 0.115s\n",
      "  training loss (in-iteration):\t\t0.437109\n",
      "  train accuracy:\t\t78.33 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.435842\n",
      "  train accuracy:\t\t78.67 %\n",
      "Epoch 337 of 1000 took 0.117s\n",
      "  training loss (in-iteration):\t\t0.434575\n",
      "  train accuracy:\t\t78.67 %\n",
      "Epoch 338 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.433308\n",
      "  train accuracy:\t\t78.67 %\n",
      "Epoch 339 of 1000 took 0.126s\n",
      "  training loss (in-iteration):\t\t0.432046\n",
      "  train accuracy:\t\t78.67 %\n",
      "Epoch 340 of 1000 took 0.119s\n",
      "  training loss (in-iteration):\t\t0.430786\n",
      "  train accuracy:\t\t78.67 %\n",
      "Epoch 341 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.429532\n",
      "  train accuracy:\t\t79.00 %\n",
      "Epoch 342 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.428274\n",
      "  train accuracy:\t\t79.00 %\n",
      "Epoch 343 of 1000 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.427013\n",
      "  train accuracy:\t\t78.67 %\n",
      "Epoch 344 of 1000 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.425756\n",
      "  train accuracy:\t\t79.00 %\n",
      "Epoch 345 of 1000 took 0.125s\n",
      "  training loss (in-iteration):\t\t0.424496\n",
      "  train accuracy:\t\t79.67 %\n",
      "Epoch 346 of 1000 took 0.126s\n",
      "  training loss (in-iteration):\t\t0.423247\n",
      "  train accuracy:\t\t80.00 %\n",
      "Epoch 347 of 1000 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.421993\n",
      "  train accuracy:\t\t80.33 %\n",
      "Epoch 348 of 1000 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.420747\n",
      "  train accuracy:\t\t80.33 %\n",
      "Epoch 349 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.419501\n",
      "  train accuracy:\t\t81.33 %\n",
      "Epoch 350 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.418256\n",
      "  train accuracy:\t\t80.67 %\n",
      "Epoch 351 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.417014\n",
      "  train accuracy:\t\t82.33 %\n",
      "Epoch 352 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.415773\n",
      "  train accuracy:\t\t82.33 %\n",
      "Epoch 353 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.414535\n",
      "  train accuracy:\t\t82.33 %\n",
      "Epoch 354 of 1000 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.413297\n",
      "  train accuracy:\t\t82.33 %\n",
      "Epoch 355 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.412070\n",
      "  train accuracy:\t\t82.33 %\n",
      "Epoch 356 of 1000 took 0.115s\n",
      "  training loss (in-iteration):\t\t0.410850\n",
      "  train accuracy:\t\t82.67 %\n",
      "Epoch 357 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.409624\n",
      "  train accuracy:\t\t82.33 %\n",
      "Epoch 358 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.408409\n",
      "  train accuracy:\t\t82.33 %\n",
      "Epoch 359 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.407189\n",
      "  train accuracy:\t\t82.33 %\n",
      "Epoch 360 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.405977\n",
      "  train accuracy:\t\t82.33 %\n",
      "Epoch 361 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.404757\n",
      "  train accuracy:\t\t82.33 %\n",
      "Epoch 362 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.403531\n",
      "  train accuracy:\t\t82.33 %\n",
      "Epoch 363 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.402301\n",
      "  train accuracy:\t\t82.67 %\n",
      "Epoch 364 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.401072\n",
      "  train accuracy:\t\t82.67 %\n",
      "Epoch 365 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.399859\n",
      "  train accuracy:\t\t83.00 %\n",
      "Epoch 366 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.398654\n",
      "  train accuracy:\t\t83.00 %\n",
      "Epoch 367 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.397436\n",
      "  train accuracy:\t\t83.00 %\n",
      "Epoch 368 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.396227\n",
      "  train accuracy:\t\t83.67 %\n",
      "Epoch 369 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.395029\n",
      "  train accuracy:\t\t83.33 %\n",
      "Epoch 370 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.393841\n",
      "  train accuracy:\t\t83.67 %\n",
      "Epoch 371 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.392661\n",
      "  train accuracy:\t\t83.67 %\n",
      "Epoch 372 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.391481\n",
      "  train accuracy:\t\t84.00 %\n",
      "Epoch 373 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.390306\n",
      "  train accuracy:\t\t84.00 %\n",
      "Epoch 374 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.389131\n",
      "  train accuracy:\t\t84.00 %\n",
      "Epoch 375 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.387962\n",
      "  train accuracy:\t\t84.33 %\n",
      "Epoch 376 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.386794\n",
      "  train accuracy:\t\t84.33 %\n",
      "Epoch 377 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.385649\n",
      "  train accuracy:\t\t84.33 %\n",
      "Epoch 378 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.384583\n",
      "  train accuracy:\t\t84.33 %\n",
      "Epoch 379 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.383489\n",
      "  train accuracy:\t\t85.33 %\n",
      "Epoch 380 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.382401\n",
      "  train accuracy:\t\t84.33 %\n",
      "Epoch 381 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.381331\n",
      "  train accuracy:\t\t86.00 %\n",
      "Epoch 382 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.380230\n",
      "  train accuracy:\t\t84.33 %\n",
      "Epoch 383 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.379075\n",
      "  train accuracy:\t\t86.67 %\n",
      "Epoch 384 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.377907\n",
      "  train accuracy:\t\t84.67 %\n",
      "Epoch 385 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.376753\n",
      "  train accuracy:\t\t86.33 %\n",
      "Epoch 386 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.375584\n",
      "  train accuracy:\t\t85.00 %\n",
      "Epoch 387 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.374455\n",
      "  train accuracy:\t\t85.00 %\n",
      "Epoch 388 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.373390\n",
      "  train accuracy:\t\t86.33 %\n",
      "Epoch 389 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.372384\n",
      "  train accuracy:\t\t85.33 %\n",
      "Epoch 390 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.371349\n",
      "  train accuracy:\t\t87.00 %\n",
      "Epoch 391 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.370265\n",
      "  train accuracy:\t\t85.33 %\n",
      "Epoch 392 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.369137\n",
      "  train accuracy:\t\t86.67 %\n",
      "Epoch 393 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.368025\n",
      "  train accuracy:\t\t86.00 %\n",
      "Epoch 394 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.366957\n",
      "  train accuracy:\t\t86.33 %\n",
      "Epoch 395 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.365938\n",
      "  train accuracy:\t\t87.00 %\n",
      "Epoch 396 of 1000 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.364921\n",
      "  train accuracy:\t\t85.33 %\n",
      "Epoch 397 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.363899\n",
      "  train accuracy:\t\t87.00 %\n",
      "Epoch 398 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.362860\n",
      "  train accuracy:\t\t86.33 %\n",
      "Epoch 399 of 1000 took 0.087s\n",
      "  training loss (in-iteration):\t\t0.361770\n",
      "  train accuracy:\t\t87.00 %\n",
      "Epoch 400 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.360748\n",
      "  train accuracy:\t\t86.33 %\n",
      "Epoch 401 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.359722\n",
      "  train accuracy:\t\t87.33 %\n",
      "Epoch 402 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.358653\n",
      "  train accuracy:\t\t87.33 %\n",
      "Epoch 403 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.357669\n",
      "  train accuracy:\t\t86.33 %\n",
      "Epoch 404 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.356651\n",
      "  train accuracy:\t\t87.33 %\n",
      "Epoch 405 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.355590\n",
      "  train accuracy:\t\t86.67 %\n",
      "Epoch 406 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.354582\n",
      "  train accuracy:\t\t87.67 %\n",
      "Epoch 407 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.353569\n",
      "  train accuracy:\t\t87.33 %\n",
      "Epoch 408 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.352519\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 409 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.351525\n",
      "  train accuracy:\t\t87.67 %\n",
      "Epoch 410 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.350549\n",
      "  train accuracy:\t\t87.67 %\n",
      "Epoch 411 of 1000 took 0.089s\n",
      "  training loss (in-iteration):\t\t0.349530\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 412 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.348534\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 413 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.347561\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 414 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.346576\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 415 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.345603\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 416 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.344651\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 417 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.343699\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 418 of 1000 took 0.087s\n",
      "  training loss (in-iteration):\t\t0.342731\n",
      "  train accuracy:\t\t88.00 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.341787\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 420 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.340881\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 421 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.339942\n",
      "  train accuracy:\t\t88.33 %\n",
      "Epoch 422 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.339018\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 423 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.338145\n",
      "  train accuracy:\t\t88.33 %\n",
      "Epoch 424 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.337352\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 425 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.336701\n",
      "  train accuracy:\t\t87.33 %\n",
      "Epoch 426 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.336180\n",
      "  train accuracy:\t\t87.67 %\n",
      "Epoch 427 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.335606\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 428 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.334475\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 429 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.333053\n",
      "  train accuracy:\t\t88.67 %\n",
      "Epoch 430 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.331909\n",
      "  train accuracy:\t\t88.33 %\n",
      "Epoch 431 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.331355\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 432 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.330784\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 433 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.329700\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 434 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.328579\n",
      "  train accuracy:\t\t88.33 %\n",
      "Epoch 435 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.327855\n",
      "  train accuracy:\t\t89.00 %\n",
      "Epoch 436 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.327268\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 437 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.326432\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 438 of 1000 took 0.115s\n",
      "  training loss (in-iteration):\t\t0.325397\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 439 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.324601\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 440 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.323983\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 441 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.323219\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 442 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.322298\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 443 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.321466\n",
      "  train accuracy:\t\t88.67 %\n",
      "Epoch 444 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.320808\n",
      "  train accuracy:\t\t88.00 %\n",
      "Epoch 445 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.320094\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 446 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.319245\n",
      "  train accuracy:\t\t88.33 %\n",
      "Epoch 447 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.318414\n",
      "  train accuracy:\t\t88.67 %\n",
      "Epoch 448 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.317689\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 449 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.316992\n",
      "  train accuracy:\t\t88.67 %\n",
      "Epoch 450 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.316251\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 451 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.315460\n",
      "  train accuracy:\t\t89.00 %\n",
      "Epoch 452 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.314696\n",
      "  train accuracy:\t\t89.00 %\n",
      "Epoch 453 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.313994\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 454 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.313332\n",
      "  train accuracy:\t\t88.67 %\n",
      "Epoch 455 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.312616\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 456 of 1000 took 0.083s\n",
      "  training loss (in-iteration):\t\t0.311838\n",
      "  train accuracy:\t\t88.67 %\n",
      "Epoch 457 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.311091\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 458 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.310410\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 459 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.309741\n",
      "  train accuracy:\t\t89.00 %\n",
      "Epoch 460 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.309020\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 461 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.308277\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 462 of 1000 took 0.088s\n",
      "  training loss (in-iteration):\t\t0.307563\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 463 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.306895\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 464 of 1000 took 0.093s\n",
      "  training loss (in-iteration):\t\t0.306206\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 465 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.305496\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 466 of 1000 took 0.085s\n",
      "  training loss (in-iteration):\t\t0.304794\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 467 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.304116\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 468 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.303443\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 469 of 1000 took 0.090s\n",
      "  training loss (in-iteration):\t\t0.302772\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 470 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.302092\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 471 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.301392\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 472 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.300727\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 473 of 1000 took 0.091s\n",
      "  training loss (in-iteration):\t\t0.300069\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 474 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.299404\n",
      "  train accuracy:\t\t89.33 %\n",
      "Epoch 475 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.298740\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 476 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.298081\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 477 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.297421\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 478 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.296772\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 479 of 1000 took 0.095s\n",
      "  training loss (in-iteration):\t\t0.296143\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 480 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.295512\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 481 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.294866\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 482 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.294220\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 483 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.293578\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 484 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.292945\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 485 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.292315\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 486 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.291688\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 487 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.291066\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 488 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.290444\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 489 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.289843\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 490 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.289231\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 491 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.288609\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 492 of 1000 took 0.092s\n",
      "  training loss (in-iteration):\t\t0.287997\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 493 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.287404\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 494 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.286797\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 495 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.286176\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 496 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.285589\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 497 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.284998\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 498 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.284398\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 499 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.283829\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 500 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.283264\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 501 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.282688\n",
      "  train accuracy:\t\t89.67 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 502 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.282127\n",
      "  train accuracy:\t\t90.33 %\n",
      "Epoch 503 of 1000 took 0.117s\n",
      "  training loss (in-iteration):\t\t0.281581\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 504 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.281034\n",
      "  train accuracy:\t\t90.33 %\n",
      "Epoch 505 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.280493\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 506 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.279972\n",
      "  train accuracy:\t\t90.67 %\n",
      "Epoch 507 of 1000 took 0.119s\n",
      "  training loss (in-iteration):\t\t0.279447\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 508 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.278908\n",
      "  train accuracy:\t\t90.67 %\n",
      "Epoch 509 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.278349\n",
      "  train accuracy:\t\t90.33 %\n",
      "Epoch 510 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.277754\n",
      "  train accuracy:\t\t90.67 %\n",
      "Epoch 511 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.277120\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 512 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.276496\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 513 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.275896\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 514 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.275324\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 515 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.274791\n",
      "  train accuracy:\t\t90.33 %\n",
      "Epoch 516 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.274255\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 517 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.273734\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 518 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.273212\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 519 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.272684\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 520 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.272186\n",
      "  train accuracy:\t\t90.33 %\n",
      "Epoch 521 of 1000 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.271680\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 522 of 1000 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.271169\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 523 of 1000 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.270677\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 524 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.270155\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 525 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.269592\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 526 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.269061\n",
      "  train accuracy:\t\t90.33 %\n",
      "Epoch 527 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.268533\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 528 of 1000 took 0.115s\n",
      "  training loss (in-iteration):\t\t0.267953\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 529 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.267384\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 530 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.266881\n",
      "  train accuracy:\t\t90.33 %\n",
      "Epoch 531 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.266345\n",
      "  train accuracy:\t\t90.67 %\n",
      "Epoch 532 of 1000 took 0.117s\n",
      "  training loss (in-iteration):\t\t0.265770\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 533 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.265232\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 534 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.264715\n",
      "  train accuracy:\t\t90.33 %\n",
      "Epoch 535 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.264175\n",
      "  train accuracy:\t\t90.67 %\n",
      "Epoch 536 of 1000 took 0.119s\n",
      "  training loss (in-iteration):\t\t0.263640\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 537 of 1000 took 0.126s\n",
      "  training loss (in-iteration):\t\t0.263157\n",
      "  train accuracy:\t\t90.33 %\n",
      "Epoch 538 of 1000 took 0.119s\n",
      "  training loss (in-iteration):\t\t0.262716\n",
      "  train accuracy:\t\t90.67 %\n",
      "Epoch 539 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.262271\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 540 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.261807\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 541 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.261415\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 542 of 1000 took 0.117s\n",
      "  training loss (in-iteration):\t\t0.260987\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 543 of 1000 took 0.119s\n",
      "  training loss (in-iteration):\t\t0.260493\n",
      "  train accuracy:\t\t89.67 %\n",
      "Epoch 544 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.259995\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 545 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.259406\n",
      "  train accuracy:\t\t90.00 %\n",
      "Epoch 546 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.258752\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 547 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.258160\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 548 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.257698\n",
      "  train accuracy:\t\t90.67 %\n",
      "Epoch 549 of 1000 took 0.122s\n",
      "  training loss (in-iteration):\t\t0.257309\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 550 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.256921\n",
      "  train accuracy:\t\t90.33 %\n",
      "Epoch 551 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.256479\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 552 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.255962\n",
      "  train accuracy:\t\t90.67 %\n",
      "Epoch 553 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.255412\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 554 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.254922\n",
      "  train accuracy:\t\t90.67 %\n",
      "Epoch 555 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.254410\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 556 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.253928\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 557 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.253508\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 558 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.253106\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 559 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.252630\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 560 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.252150\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 561 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.251688\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 562 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.251257\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 563 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.250784\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 564 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.250324\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 565 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.249911\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 566 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.249496\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 567 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.249044\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 568 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.248614\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 569 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.248176\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 570 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.247732\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 571 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.247301\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 572 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.246872\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 573 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.246441\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 574 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.246016\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 575 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.245598\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 576 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.245182\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 577 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.244760\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 578 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.244354\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 579 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.243947\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 580 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.243531\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 581 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.243115\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 582 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.242717\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 583 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.242335\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 584 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.241922\n",
      "  train accuracy:\t\t91.33 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 585 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.241509\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 586 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.241136\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 587 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.240755\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 588 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.240365\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 589 of 1000 took 0.094s\n",
      "  training loss (in-iteration):\t\t0.239993\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 590 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.239625\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 591 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.239276\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 592 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.238964\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 593 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.238687\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 594 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.238405\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 595 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.238146\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 596 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.237859\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 597 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.237528\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 598 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.237067\n",
      "  train accuracy:\t\t91.00 %\n",
      "Epoch 599 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.236504\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 600 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.235948\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 601 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.235481\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 602 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.235136\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 603 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.234869\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 604 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.234623\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 605 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.234315\n",
      "  train accuracy:\t\t91.33 %\n",
      "Epoch 606 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.233911\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 607 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.233466\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 608 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.233045\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 609 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.232673\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 610 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.232356\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 611 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.232070\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 612 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.231761\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 613 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.231428\n",
      "  train accuracy:\t\t91.67 %\n",
      "Epoch 614 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.231084\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 615 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.230713\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 616 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.230330\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 617 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.229972\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 618 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.229649\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 619 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.229332\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 620 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.229009\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 621 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.228701\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 622 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.228391\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 623 of 1000 took 0.096s\n",
      "  training loss (in-iteration):\t\t0.228066\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 624 of 1000 took 0.117s\n",
      "  training loss (in-iteration):\t\t0.227727\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 625 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.227390\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 626 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.227057\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 627 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.226728\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 628 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.226407\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 629 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.226087\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 630 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.225772\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 631 of 1000 took 0.126s\n",
      "  training loss (in-iteration):\t\t0.225461\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 632 of 1000 took 0.125s\n",
      "  training loss (in-iteration):\t\t0.225153\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 633 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.224851\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 634 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.224551\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 635 of 1000 took 0.119s\n",
      "  training loss (in-iteration):\t\t0.224252\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 636 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.223961\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 637 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.223675\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 638 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.223389\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 639 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.223122\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 640 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.222839\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 641 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.222567\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 642 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.222265\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 643 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.221961\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 644 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.221625\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 645 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.221282\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 646 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.220939\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 647 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.220605\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 648 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.220293\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 649 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.219998\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 650 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.219709\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 651 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.219419\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 652 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.219127\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 653 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.218847\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 654 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.218576\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 655 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.218301\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 656 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.218015\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 657 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.217735\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 658 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.217472\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 659 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.217216\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 660 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.216968\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 661 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.216720\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 662 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.216494\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 663 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.216240\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 664 of 1000 took 0.099s\n",
      "  training loss (in-iteration):\t\t0.215981\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 665 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.215713\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 666 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.215421\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 667 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.215097\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 668 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.214783\n",
      "  train accuracy:\t\t92.67 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.214476\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 670 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.214181\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 671 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.213872\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 672 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.213589\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 673 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.213329\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 674 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.213071\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 675 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.212817\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 676 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.212582\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 677 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.212345\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 678 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.212100\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 679 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.211858\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 680 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.211601\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 681 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.211342\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 682 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.211084\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 683 of 1000 took 0.097s\n",
      "  training loss (in-iteration):\t\t0.210821\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 684 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.210554\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 685 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.210298\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 686 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.210041\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 687 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.209784\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 688 of 1000 took 0.098s\n",
      "  training loss (in-iteration):\t\t0.209524\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 689 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.209269\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 690 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.209023\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 691 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.208785\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 692 of 1000 took 0.115s\n",
      "  training loss (in-iteration):\t\t0.208521\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 693 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.208265\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 694 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.208020\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 695 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.207766\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 696 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.207508\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 697 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.207253\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 698 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.207017\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 699 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.206801\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 700 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.206555\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 701 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.206292\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 702 of 1000 took 0.117s\n",
      "  training loss (in-iteration):\t\t0.206049\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 703 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.205826\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 704 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.205597\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 705 of 1000 took 0.122s\n",
      "  training loss (in-iteration):\t\t0.205347\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 706 of 1000 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.205093\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 707 of 1000 took 0.122s\n",
      "  training loss (in-iteration):\t\t0.204855\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 708 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.204633\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 709 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.204413\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 710 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.204173\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 711 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.203938\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 712 of 1000 took 0.126s\n",
      "  training loss (in-iteration):\t\t0.203729\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 713 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.203542\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 714 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.203342\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 715 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.203142\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 716 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.202998\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 717 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.202943\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 718 of 1000 took 0.115s\n",
      "  training loss (in-iteration):\t\t0.202979\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 719 of 1000 took 0.125s\n",
      "  training loss (in-iteration):\t\t0.203120\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 720 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.203223\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 721 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.203242\n",
      "  train accuracy:\t\t94.33 %\n",
      "Epoch 722 of 1000 took 0.125s\n",
      "  training loss (in-iteration):\t\t0.202797\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 723 of 1000 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.201922\n",
      "  train accuracy:\t\t94.33 %\n",
      "Epoch 724 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.201084\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 725 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.200899\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 726 of 1000 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.201137\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 727 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.201182\n",
      "  train accuracy:\t\t92.00 %\n",
      "Epoch 728 of 1000 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.200798\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 729 of 1000 took 0.125s\n",
      "  training loss (in-iteration):\t\t0.200201\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 730 of 1000 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.199801\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 731 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.199740\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 732 of 1000 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.199787\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 733 of 1000 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.199600\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 734 of 1000 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.199107\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 735 of 1000 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.198742\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 736 of 1000 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.198716\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 737 of 1000 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.198687\n",
      "  train accuracy:\t\t92.33 %\n",
      "Epoch 738 of 1000 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.198412\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 739 of 1000 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.198006\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 740 of 1000 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.197737\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 741 of 1000 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.197644\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 742 of 1000 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.197537\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 743 of 1000 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.197266\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 744 of 1000 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.196937\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 745 of 1000 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.196725\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 746 of 1000 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.196612\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 747 of 1000 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.196460\n",
      "  train accuracy:\t\t92.67 %\n",
      "Epoch 748 of 1000 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.196217\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 749 of 1000 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.195943\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 750 of 1000 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.195733\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 751 of 1000 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.195580\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 752 of 1000 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.195405\n",
      "  train accuracy:\t\t93.00 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 753 of 1000 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.195188\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 754 of 1000 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.194963\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 755 of 1000 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.194772\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 756 of 1000 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.194594\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 757 of 1000 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.194421\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 758 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.194227\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 759 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.194013\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 760 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.193813\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 761 of 1000 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.193650\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 762 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.193465\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 763 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.193265\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 764 of 1000 took 0.126s\n",
      "  training loss (in-iteration):\t\t0.193079\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 765 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.192897\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 766 of 1000 took 0.125s\n",
      "  training loss (in-iteration):\t\t0.192709\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 767 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.192522\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 768 of 1000 took 0.125s\n",
      "  training loss (in-iteration):\t\t0.192348\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 769 of 1000 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.192154\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 770 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.191953\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 771 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.191763\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 772 of 1000 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.191582\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 773 of 1000 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.191408\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 774 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.191242\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 775 of 1000 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.191084\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 776 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.190895\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 777 of 1000 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.190700\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 778 of 1000 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.190508\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 779 of 1000 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.190320\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 780 of 1000 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.190133\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 781 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.189955\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 782 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.189787\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 783 of 1000 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.189608\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 784 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.189435\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 785 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.189260\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 786 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.189083\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 787 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.188905\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 788 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.188735\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 789 of 1000 took 0.119s\n",
      "  training loss (in-iteration):\t\t0.188567\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 790 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.188385\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 791 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.188188\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 792 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.188011\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 793 of 1000 took 0.125s\n",
      "  training loss (in-iteration):\t\t0.187844\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 794 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.187679\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 795 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.187509\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 796 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.187342\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 797 of 1000 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.187179\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 798 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.187033\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 799 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.186880\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 800 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.186680\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 801 of 1000 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.186475\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 802 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.186299\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 803 of 1000 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.186159\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 804 of 1000 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.186012\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 805 of 1000 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.185838\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 806 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.185670\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 807 of 1000 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.185522\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 808 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.185365\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 809 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.185203\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 810 of 1000 took 0.125s\n",
      "  training loss (in-iteration):\t\t0.184989\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 811 of 1000 took 0.126s\n",
      "  training loss (in-iteration):\t\t0.184787\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 812 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.184649\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 813 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.184494\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 814 of 1000 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.184323\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 815 of 1000 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.184142\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 816 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.183975\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 817 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.183826\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 818 of 1000 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.183675\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 819 of 1000 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.183494\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 820 of 1000 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.183310\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 821 of 1000 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.183183\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 822 of 1000 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.183050\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 823 of 1000 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.182880\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 824 of 1000 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.182729\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 825 of 1000 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.182593\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 826 of 1000 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.182483\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 827 of 1000 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.182309\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 828 of 1000 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.182093\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 829 of 1000 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.181880\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 830 of 1000 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.181702\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 831 of 1000 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.181535\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 832 of 1000 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.181376\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 833 of 1000 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.181240\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 834 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.181147\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 835 of 1000 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.181033\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 836 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.180917\n",
      "  train accuracy:\t\t93.67 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837 of 1000 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.180774\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 838 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.180684\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 839 of 1000 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.180567\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 840 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.180368\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 841 of 1000 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.180138\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 842 of 1000 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.179888\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 843 of 1000 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.179657\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 844 of 1000 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.179465\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 845 of 1000 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.179293\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 846 of 1000 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.179159\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 847 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.179072\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 848 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.178966\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 849 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.178839\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 850 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.178707\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 851 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.178559\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 852 of 1000 took 0.115s\n",
      "  training loss (in-iteration):\t\t0.178385\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 853 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.178180\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 854 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.177965\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 855 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.177772\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 856 of 1000 took 0.115s\n",
      "  training loss (in-iteration):\t\t0.177604\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 857 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.177463\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 858 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.177312\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 859 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.177184\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 860 of 1000 took 0.119s\n",
      "  training loss (in-iteration):\t\t0.177089\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 861 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.176967\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 862 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.176824\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 863 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.176664\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 864 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.176516\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 865 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.176354\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 866 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.176173\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 867 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.175993\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 868 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.175821\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 869 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.175660\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 870 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.175514\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 871 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.175359\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 872 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.175210\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 873 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.175102\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 874 of 1000 took 0.119s\n",
      "  training loss (in-iteration):\t\t0.175010\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 875 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.174896\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 876 of 1000 took 0.117s\n",
      "  training loss (in-iteration):\t\t0.174788\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 877 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.174693\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 878 of 1000 took 0.115s\n",
      "  training loss (in-iteration):\t\t0.174567\n",
      "  train accuracy:\t\t93.00 %\n",
      "Epoch 879 of 1000 took 0.122s\n",
      "  training loss (in-iteration):\t\t0.174425\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 880 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.174272\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 881 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.174136\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 882 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.173993\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 883 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.173793\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 884 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.173556\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 885 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.173395\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 886 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.173270\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 887 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.173092\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 888 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.172900\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 889 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.172762\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 890 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.172670\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 891 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.172551\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 892 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.172373\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 893 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.172200\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 894 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.172074\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 895 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.171941\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 896 of 1000 took 0.104s\n",
      "  training loss (in-iteration):\t\t0.171786\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 897 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.171641\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 898 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.171522\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 899 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.171400\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 900 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.171281\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 901 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.171148\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 902 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.171016\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 903 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.170891\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 904 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.170777\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 905 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.170654\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 906 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.170523\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 907 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.170399\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 908 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.170316\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 909 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.170249\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 910 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.170197\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 911 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.170128\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 912 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.170045\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 913 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.169950\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 914 of 1000 took 0.110s\n",
      "  training loss (in-iteration):\t\t0.169795\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 915 of 1000 took 0.115s\n",
      "  training loss (in-iteration):\t\t0.169536\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 916 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.169252\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 917 of 1000 took 0.111s\n",
      "  training loss (in-iteration):\t\t0.169035\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 918 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.168885\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 919 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.168730\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 920 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.168566\n",
      "  train accuracy:\t\t93.67 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 921 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.168428\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 922 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.168335\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 923 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.168237\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 924 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.168114\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 925 of 1000 took 0.100s\n",
      "  training loss (in-iteration):\t\t0.167953\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 926 of 1000 took 0.103s\n",
      "  training loss (in-iteration):\t\t0.167796\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 927 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.167667\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 928 of 1000 took 0.102s\n",
      "  training loss (in-iteration):\t\t0.167550\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 929 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.167410\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 930 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.167264\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 931 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.167137\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 932 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.167031\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 933 of 1000 took 0.101s\n",
      "  training loss (in-iteration):\t\t0.166917\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 934 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.166792\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 935 of 1000 took 0.108s\n",
      "  training loss (in-iteration):\t\t0.166675\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 936 of 1000 took 0.107s\n",
      "  training loss (in-iteration):\t\t0.166593\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 937 of 1000 took 0.112s\n",
      "  training loss (in-iteration):\t\t0.166492\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 938 of 1000 took 0.105s\n",
      "  training loss (in-iteration):\t\t0.166354\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 939 of 1000 took 0.106s\n",
      "  training loss (in-iteration):\t\t0.166236\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 940 of 1000 took 0.109s\n",
      "  training loss (in-iteration):\t\t0.166145\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 941 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.166021\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 942 of 1000 took 0.117s\n",
      "  training loss (in-iteration):\t\t0.165871\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 943 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.165708\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 944 of 1000 took 0.125s\n",
      "  training loss (in-iteration):\t\t0.165561\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 945 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.165419\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 946 of 1000 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.165285\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 947 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.165158\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 948 of 1000 took 0.117s\n",
      "  training loss (in-iteration):\t\t0.165032\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 949 of 1000 took 0.113s\n",
      "  training loss (in-iteration):\t\t0.164905\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 950 of 1000 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.164779\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 951 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.164657\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 952 of 1000 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.164537\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 953 of 1000 took 0.120s\n",
      "  training loss (in-iteration):\t\t0.164413\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 954 of 1000 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.164289\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 955 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.164179\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 956 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.164075\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 957 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.163983\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 958 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.163896\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 959 of 1000 took 0.115s\n",
      "  training loss (in-iteration):\t\t0.163809\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 960 of 1000 took 0.121s\n",
      "  training loss (in-iteration):\t\t0.163754\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 961 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.163717\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 962 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.163683\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 963 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.163626\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 964 of 1000 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.163545\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 965 of 1000 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.163475\n",
      "  train accuracy:\t\t94.33 %\n",
      "Epoch 966 of 1000 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.163356\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 967 of 1000 took 0.125s\n",
      "  training loss (in-iteration):\t\t0.163173\n",
      "  train accuracy:\t\t94.33 %\n",
      "Epoch 968 of 1000 took 0.119s\n",
      "  training loss (in-iteration):\t\t0.162935\n",
      "  train accuracy:\t\t93.33 %\n",
      "Epoch 969 of 1000 took 0.119s\n",
      "  training loss (in-iteration):\t\t0.162677\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 970 of 1000 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.162450\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 971 of 1000 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.162284\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 972 of 1000 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.162159\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 973 of 1000 took 0.114s\n",
      "  training loss (in-iteration):\t\t0.162063\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 974 of 1000 took 0.122s\n",
      "  training loss (in-iteration):\t\t0.161997\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 975 of 1000 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.161943\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 976 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.161866\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 977 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.161735\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 978 of 1000 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.161589\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 979 of 1000 took 0.124s\n",
      "  training loss (in-iteration):\t\t0.161436\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 980 of 1000 took 0.122s\n",
      "  training loss (in-iteration):\t\t0.161290\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 981 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.161146\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 982 of 1000 took 0.118s\n",
      "  training loss (in-iteration):\t\t0.160996\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 983 of 1000 took 0.117s\n",
      "  training loss (in-iteration):\t\t0.160873\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 984 of 1000 took 0.116s\n",
      "  training loss (in-iteration):\t\t0.160776\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 985 of 1000 took 0.123s\n",
      "  training loss (in-iteration):\t\t0.160684\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 986 of 1000 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.160574\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 987 of 1000 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.160460\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 988 of 1000 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.160357\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 989 of 1000 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.160254\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 990 of 1000 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.160124\n",
      "  train accuracy:\t\t94.33 %\n",
      "Epoch 991 of 1000 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.159994\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 992 of 1000 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.159890\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 993 of 1000 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.159792\n",
      "  train accuracy:\t\t94.33 %\n",
      "Epoch 994 of 1000 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.159666\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 995 of 1000 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.159526\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 996 of 1000 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.159415\n",
      "  train accuracy:\t\t94.33 %\n",
      "Epoch 997 of 1000 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.159317\n",
      "  train accuracy:\t\t93.67 %\n",
      "Epoch 998 of 1000 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.159199\n",
      "  train accuracy:\t\t94.33 %\n",
      "Epoch 999 of 1000 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.159070\n",
      "  train accuracy:\t\t94.00 %\n",
      "Epoch 1000 of 1000 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.158956\n",
      "  train accuracy:\t\t94.00 %\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 1000 # amount of passes through the data\n",
    "\n",
    "batch_size = 300 # number of samples processed at each function call\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #initialize global wariables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        for batch in iterate_minibatches(X, y,batch_size):\n",
    "            inputs, targets = batch\n",
    "\n",
    "            _, train_err_batch, _ = sess.run(\n",
    "                [train_step, loss, update_accuracy],\n",
    "                feed_dict={input_X: inputs, target_y:targets}\n",
    "            )\n",
    "            train_err += train_err_batch\n",
    "            train_batches += 1\n",
    "        train_acc = sess.run(accuracy)\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "        print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "            train_acc * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
